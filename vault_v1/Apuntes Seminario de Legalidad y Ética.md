#8semester 
# Clase 1

## Derecho

¬øQu√© es?: No solamente son las reglas escritas. Son reglas y principios flexibles (esto por los avances de la tecnolog√≠a). El derecho no es justo s√≥lo por ser derecho.

**Principio principal:** dignidad

- Imperativo categ√≥rico de Kant: el ser humano es un fin y nunca debe de ser tratado como medio

### Constituci√≥n 
- Principio de Legalidad: solamente puedes hacer lo que la ley te dice. 
- Principio de Seguridad Jur√≠dica: tener la certeza de que se va a actuar seg√∫n la ley.
	- Combate la incertidumbre del derecho.
### DDHH
- **Art√≠culo 1:** basados en la dignidad de las personas
- *def:* principios que est√°n contenidos en una constituci√≥n o en tratados internacionales dirigidos a la protecci√≥n de los seres humanos.
### Tratados Internacionales
1. Individuales 
2. Sociales
3. Ambientales
4. TICS 

Una empresa tiene: 
1. Pol√≠tica
2. Procedimientos 
3. Procesos

Un gobierno hace: 
- Pol√≠ticas P√∫blicas: acciones a largo plazo para resolver una problem√°tica, que impacta a la poblaci√≥n 

**Art√≠culo 6 de la Cons. Pol:** derecho de acceso a internet 
- ¬øA qui√©n corresponde?: al estado
- Estado: Estructura que d vida al conjunto de instituciones pol√≠ticas modernas y de las que se desprenden el sistema pol√≠tico, r√©gimen, gobierno y administraci√≥n pol√≠tica. 
- ¬øQu√© acci√≥n?: garantizar el acceso a internet a las personas.
- ¬øC√≥mo?
	1. Conseguir informaci√≥n 
	2. Hablar con el de redes 
	3. Hablar con el de obras
	4. Modems
	5. Auditorias

Divisi√≥n de poderes: 
1. Ejecutivo: hace pol√≠ticas p√∫blicas
2. Legislativo: aprueba el uso de recursos (budget)
3. Judicial: rol reactivo y de supervisi√≥n en las pol√≠ticas p√∫blicas

# Clase 2

### Organos aut√≥nomos

Con autonom√≠a presupuestal y de gesti√≥n.

**INAI**

- Transparencia
- Protecci√≥n de los datos personales
- INE
- CNDH
- Banco de M√©xico

El INAI y la CNDH van a tener que intervenir por el avance de la Inteligencia Artificial

Varios tipos de IA, el tradicional son los sistemas expertos decisionales,

Dos corrientes de la IA:

1. L√≥gica, de ah√≠ salen los sistemas expertos decisionales.
2. Biolog√≠a: redes neuronales.

1970-1990 Invierno de la IA:

- Padres del AI: Hinton.
    
- En 1996 crea las redes neuronales convolucionales, esto llev√≥ al Deep Learning, que por su parte llev√≥ a los Large Language Models
    

Debido a las redes neuronales convolucionales tenemos el Big Data, C√≥mputo en la nube, Procesadores de alta calidad.

¬øQu√© tipo de IA impacta a derechos humanos?

RE: La biol√≥gica

## **C√≥mo se forman los algoritmos**

|Sistema Experto de Decisi√≥n|Biol√≥gicos (Deep Learning) RNCP|
|---|---|
|1. Programador|1. Usuario|
|2. Experto||
|3. Usuario||

Las RNCP crean un impacto en los sectores: privados, salud, educaci√≥n, trabajadores. Es dif√≠cil decidir a quien echarle la culpa, porque es complicado regular la tecnolog√≠a.

¬øQu√© tipo de derechos tienen las m√°quinas?

Primero se debe de preguntar si toman o no decisiones que afecten al entorno.

Agencia-agente: aquel ente que tiene la capacidad de cambiar el mundo.

Responsabilidad jur√≠dica:

1. Responsabilidad subjetiva: la que directamente hace la persona a trav√©s de su voluntad que impacto de forma negativa
2. ‚Äú Objetiva: se impacta de forma negativa pero la persona no participa directamente.
    1. Ejemplo: caso Williams, padre-hijo, la responsabilidad es del padre.
    2. Ejemplo: caso Tesla, el conductor es el responsable directo.
3. ‚Äú Patrimonial del Estado: cuando un coche impacta por un bache descuidado.

Tipos de razonamiento

1. Inductivo
2. Deductive
3. Abductivo: infiere la mejor explicaci√≥n o la hip√≥tesis m√°s probable para un conjunto de observaciones o datos.
    1. Es el que hace m√°s lata en el derecho.
    2. **Toma de decisiones:**
        1. Utilitarismo: mayor beneficio para el mayor n√∫mero de personas
        2. Valores:
        3. Ley por encima de todo:

Se pueden hacer combinaciones entre los tres.

# Regulaciones que tienen que ver con CDA

1. **Uni√≥n Europea:** Actas
    1. IA: esta por aprobarse una ley
    2. Entornos digitales
    3. Comercio digital
        1. ‚Äú**Riesgos**‚Äù: hay riesgos positivos y negativos. Ejemplo de positivo, en el COVID a Zoom le fue super bien üëç
            
            1. **M√≠nimo**: sistema de reconocimiento, filtros de correo
            2. **Alto**: infraestructura p√∫blica, productos sanitarios, acceso a educaci√≥n, polic√≠a, migraci√≥n, justicia, democracia, biometricos, categorizaci√≥n (perfilamiento de negocio), y reconocimiento de emociones.
            3. **Inadmisible**: reconocimiento de emociones en lugar de trabajo, id biometrico remoto en lugares p√∫blicos, manipulaci√≥n de comportamiento humano, puntos de clasificaci√≥n social.
            4. **Riesgo espec√≠fico de transparencia:** claridad cuando algo ha sido creado por una IA.
        2. ¬øImpacta o no a los derechos humanos nuestro modelo de negocio?
            
        3. Toma decisiones
            
        4. Que nivel de autonom√≠a tiene ese sistema de AI
            
2. **USA:** Biden public√≥ un acuerdo para regular la IA en toda la admin p√∫blica. Tiene un sistema pol√≠tico presidencial. _Buscar orden ejecutiva de Biden sobre AI_
    1. La administraci√≥n p√∫blica son **agencias de gobierno**
    2. Regulation de la IA a trav√©s de la administraci√≥n p√∫blica
        1. Protecci√≥n de los datos de las p√∫blicas
            1. Nos llevan a los derechos humanos
3. **China:** ciberseguridad, protecci√≥n de datos, seguridad. Respeto a los valores socialistas no da√±ar el sistema, minor√≠as, informaci√≥n sexual. No discriminaci√≥n, respeto a la propiedad intelectual, I.A.G verificaci√≥n de contenido. Respeto derechos de las personas, prevenir adicciones, da√±os f√≠sicos, prohibido usar informaci√≥n privada, capacitaci√≥n del personal.
4. **Brasil:** def de un sist de AI, riesgos (toma el modelo de la UE), derecho de las personas de saber si se interactua con una AI, y de saber como es que la IA toma la decisi√≥n. Interpretabilidad, derecho a la intervenci√≥n humana. derecho a la privacidad y protecci√≥n de la data, no discriminaci√≥n, derechos de autor.
5. **Israel:** recomendaciones.
    - Adopci√≥n de una regulaci√≥n sectorial
    - Coherencia con el enfoque regulador de los principales pa√≠ses y organizaciones internacionales
    - Adopci√≥n de un enfoque basado en el riesgo
    - Utilizaci√≥n de herramientas reguladoras "blandas" que permitan un desarrollo gradual del marco regulador
    - Fomento de la cooperaci√≥n entre los sectores p√∫blico y privado.

- **Democracia:** libertad para elegir quien gobierna. La libertad es un derecho humano.

# Clase 16 02 24

*revisar apuntes para la clase de la semana pasada porque ten√≠a COVID*
## Caso 4: [[Deep fakes]] & [[Cheap-fakes]]

- El da√±o principal es la desinformaci√≥n que genera. 

## Caso 5: Literature-texts-AI

- "If you don't double check it, it becomes inmoral"
- Se debe de justificar que partes se utilizan o generan con Inteligencia Artificial 

## Caso 6: [[Cookies]] & [[FloCs]] (marketing y privacidad)

**Cookies**: informaci√≥n que usan las empresas para perfilamiento. 
- La privacidad es una restricci√≥n al uso de la informaci√≥n 
- Todos los problemas legales de la IA est√°n relacionados con la privacidad.
- **Las empresas est√°n generando su propia informaci√≥n para contraatacar la eliminaci√≥n de los cookies.** Por ejemplo, en restaurantes hacen sus cuestionarios. 

## Decisiones de las m√°quinas
### Responsabilidad jur√≠dica

- Persona y dignidad
- Libre albedr√≠o y autonom√≠a 
- Agencia -agente moral- 
- Responsabilidades y riesgos de la empresa
- Sesgos y [[auditor√≠as algor√≠tmicas]]

*tarea: buscar auditorias algoritmicas en latam*
*apuntes de esta √∫ltima clase y de la primera de  √©tica*

# Evoluci√≥n Tecnol√≥gica
*8 de marzo*
## 4ta Revoluci√≥n Tecnol√≥gica 

*Melanie Mitchell (2021) ¬øPor qu√© la IA es m√°s dif√≠cil de lo que pensamos?*

![[Pasted image 20240308103614.png]]

### Donde estamos: 

1. Alpha Go le gana a Kasparov
2. Explosi√≥n del Big Data
3. Litograf√≠a Ultravioleta
4. Geoff Hinton avance en redes neuronales profundas

**Evoluci√≥n**

1. Comunicaci√≥n 
	1. Internet, Arpanet 
	2. Open Source
2. Recabaci√≥n 
	1. Big Data
3. Almacenamiento
	1. Nube
4. Procesamiento
	1. Litograf√≠a ultravioleta extrema
5. Inversi√≥n de riesgo 
	1. Capacidad de invertir que nunca hab√≠amos tenido; inversi√≥n de riesgo. 

# Comunicaci√≥n 

## ¬øC√≥mo comunicarlo asertivamente? 

## Econom√≠a del lenguaje 

> It's all a matter of mental economy.
> 			 Daniel Kahneman

- Si bueno y breve, dos veces bueno.

## Oikos

### Administraci√≥n 

Todo comunica: 
- Voz 
- Palabras
- Ademanes
- Postura
- Gesticulaci√≥n
- Imagen

### Recursos vocales 
*agregar al FODA*

- **Volumen** (DB): intensidad  
- **Tono** (Hz): frecuencia
- **Timbre**: textura, color. Como abres y cierras la boca.  
- **Dicci√≥n** (Alta/baja definici√≥n): claridad
- **Ritmo** (Cadencia): variaci√≥n r√°pido/lento

La personalidad son todos los elementos. 

# 4ta Revoluci√≥n Industrial 

## Criterios para hablar de AGI:

1. Test de Turing 
2. Emulaci√≥n de nuestras capacidades de razonar y sentir 
3. Capacidad de m√∫ltiples funciones
4. √öltimo reto de complejidad humana autoconciencia

## Singularidad en IA

1. Desarrollo humano
2. Loop de retroalimentaci√≥n 
3. *completar*

## AGI

Para llegar a la AGI Conectando simbolismo y conectismo (*Gary Marcus*)
*Timnit Gebru*: cr√≠tica a Google, ¬øde d√≥nde sale el dinero?.
- Mucho dinero es p√∫blico, busca que la IA se use para atender problemas sociales.

# 1.2 Pensamiento ecosist√©mico 





